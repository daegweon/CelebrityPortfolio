import time
import schedule
from app.scrapers.engine import CapitolTradesScraper, SEC13FScraper
from app.db.manager import SupabaseManager

class ScrapingScheduler:
    """
    CelebrityPortfolioì˜ ë°ì´í„° ìˆ˜ì§‘ì„ ìë™í™”í•˜ëŠ” ìŠ¤ì¼€ì¤„ëŸ¬ í´ë˜ìŠ¤ì…ë‹ˆë‹¤.
    """
    def __init__(self):
        self.db = SupabaseManager()
        self.capitol_scraper = CapitolTradesScraper()
        self.sec_scraper = SEC13FScraper()

    def job_capitol_trades(self):
        """êµ­íšŒì˜ì› ê±°ë˜ ë‚´ì—­ì„ ìˆ˜ì§‘í•˜ì—¬ DBì— ì €ì¥í•˜ëŠ” ì‘ì—…"""
        print(f"[{time.strftime('%Y-%m-%d %H:%M:%S')}] Starting Capitol Trades scraping job...")
        trades = self.capitol_scraper.get_latest_trades(limit=20)
        
        for trade in trades:
            # ì‹¤ë¬´ì—ì„œëŠ” ë°ì´í„° ì¤‘ë³µ ì²´í¬ ë¡œì§ì´ í¬í•¨ë©ë‹ˆë‹¤.
            # self.db.insert_transaction(trade)
            print(f"   - Processed trade: {trade['politician']} ({trade['ticker']})")
        print("[*] Capitol Trades job completed.")

    def job_sec_13f(self):
        """ê¸°ê´€ íˆ¬ìì 13F ê³µì‹œë¥¼ í™•ì¸í•˜ê³  í¬íŠ¸í´ë¦¬ì˜¤ë¥¼ ê°±ì‹ í•˜ëŠ” ì‘ì—…"""
        print(f"[{time.strftime('%Y-%m-%d %H:%M:%S')}] Starting SEC 13F check job...")
        # ì¶”ì  ëŒ€ìƒ CIK ëª©ë¡ì„ ê°€ì ¸ì™€ì„œ ë£¨í”„ë¥¼ ë•ë‹ˆë‹¤.
        # ì˜ˆ: Warren Buffett CIK = '0001067983'
        # self.sec_scraper.fetch_filing_metadata('0001067983')
        print("[*] SEC 13F check job completed.")

    def run_forever(self):
        """ìŠ¤ì¼€ì¤„ëŸ¬ ì‹¤í–‰ ë£¨í”„"""
        # 1. êµ­íšŒì˜ì› ê±°ë˜ ë‚´ì—­ì€ ë§¤ì‹œê°„ ì²´í¬
        schedule.every(1).hours.do(self.job_capitol_trades)
        
        # 2. SEC 13F ê³µì‹œëŠ” ë§¤ì¼ 4ë²ˆ ì²´í¬ (ê³µì‹œ ì§‘ì¤‘ ê¸°ê°„ ê³ ë ¤)
        schedule.every(6).hours.do(self.job_sec_13f)
        
        # 3. í…ŒìŠ¤íŠ¸ìš©: ì¦‰ì‹œ ì‹¤í–‰ (ì„ íƒ ì‚¬í•­)
        self.job_capitol_trades()
        self.job_sec_13f()

        print("[ğŸš€] Scheduler started and running...")
        while True:
            schedule.run_pending()
            time.sleep(60)

if __name__ == "__main__":
    scheduler = ScrapingScheduler()
    scheduler.run_forever()
